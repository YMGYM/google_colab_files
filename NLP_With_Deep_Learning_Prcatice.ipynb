{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_With_Deep_Learning_Prcatice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPswWpS3keRcTHuaWFsQDkO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/google_colab_files/blob/master/NLP_With_Deep_Learning_Prcatice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QilqMbGmmR9N",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "이것은 https://wikidocs.net/24996 의 실습입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNoW8pZY0eUm",
        "colab_type": "text"
      },
      "source": [
        "# import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWf9OW3M0fzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmvJ8THj0q6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "with http.request(\"GET\", url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
        "  shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "  zip_ref.extractall(path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSPHK-Fe1ZGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf918d4a-f17b-4f1d-bf2b-ab640b690d8a"
      },
      "source": [
        "lines = pd.read_csv(\"fra.txt\", names=['src', 'tar', 'copy'], sep='\\t')\n",
        "len(lines)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtx2LlHG11Ss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "2b9b82d5-6276-47d1-b2c6-90a6b25b2c1f"
      },
      "source": [
        "lines"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "      <th>copy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178004</th>\n",
              "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178005</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178006</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178007</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178008</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178009 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      src  ...                                               copy\n",
              "0                                                     Go.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1                                                     Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "2                                                     Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "3                                                    Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4                                                    Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "...                                                   ...  ...                                                ...\n",
              "178004  Top-down economics never works, said Obama. \"T...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178005  A carbon footprint is the amount of carbon dio...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178006  Death is something that we're often discourage...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178007  Since there are usually multiple websites on a...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "178008  If someone who doesn't know your background sa...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "\n",
              "[178009 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdufWppi1_mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDRTjHID2IFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ba5f0dad-57c8-486d-bf81-148b07184289"
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23761</th>\n",
              "      <td>He took a big risk.</td>\n",
              "      <td>Il a pris un gros risque.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57305</th>\n",
              "      <td>She showed me his album.</td>\n",
              "      <td>Elle m'a montré son album.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47038</th>\n",
              "      <td>Do you believe in UFOs?</td>\n",
              "      <td>Croyez-vous aux OVNIs ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31318</th>\n",
              "      <td>Open up the package.</td>\n",
              "      <td>Ouvrez le paquet.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38301</th>\n",
              "      <td>They're not all busy.</td>\n",
              "      <td>Elles ne sont pas toutes occupées.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8529</th>\n",
              "      <td>I'm not joking.</td>\n",
              "      <td>Je ne plaisante pas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>Can I have one?</td>\n",
              "      <td>Puis-je en avoir un ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33577</th>\n",
              "      <td>You're almost right.</td>\n",
              "      <td>Vous avez presque raison.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>I'm not going.</td>\n",
              "      <td>Je ne m'en vais pas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51034</th>\n",
              "      <td>The middle one is mine.</td>\n",
              "      <td>Celui du milieu est le mien.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                 tar\n",
              "23761       He took a big risk.           Il a pris un gros risque.\n",
              "57305  She showed me his album.          Elle m'a montré son album.\n",
              "47038   Do you believe in UFOs?             Croyez-vous aux OVNIs ?\n",
              "31318      Open up the package.                   Ouvrez le paquet.\n",
              "38301     They're not all busy.  Elles ne sont pas toutes occupées.\n",
              "8529            I'm not joking.                Je ne plaisante pas.\n",
              "7316            Can I have one?               Puis-je en avoir un ?\n",
              "33577      You're almost right.           Vous avez presque raison.\n",
              "6001             I'm not going.                Je ne m'en vais pas.\n",
              "51034   The middle one is mine.        Celui du milieu est le mien."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C47CDqOhP0mG",
        "colab_type": "text"
      },
      "source": [
        "## Make Symbol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI4n40nPP2tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "762328e9-bbe2-477e-8ae6-f76f0ad00009"
      },
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t' + x + '\\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56458</th>\n",
              "      <td>I'm too sleepy to drive.</td>\n",
              "      <td>\\tJe suis trop somnolent pour conduire.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11766</th>\n",
              "      <td>Is it hazardous?</td>\n",
              "      <td>\\tEst-ce dangereux ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24292</th>\n",
              "      <td>I have a dry cough.</td>\n",
              "      <td>\\tJ'ai une toux sèche.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31722</th>\n",
              "      <td>That's a huge organ.</td>\n",
              "      <td>\\tC'est un organe gigantesque.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22502</th>\n",
              "      <td>You have problems.</td>\n",
              "      <td>\\tVous avez des problèmes.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24908</th>\n",
              "      <td>I'll call the cops.</td>\n",
              "      <td>\\tJe vais appeler les flics.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>Be content.</td>\n",
              "      <td>\\tSois satisfait !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6669</th>\n",
              "      <td>This is basic.</td>\n",
              "      <td>\\tC'est basique.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33032</th>\n",
              "      <td>What's the time now?</td>\n",
              "      <td>\\tQuelle heure est-il maintenant ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50984</th>\n",
              "      <td>The event is on Monday.</td>\n",
              "      <td>\\tL'évènement se déroule lundi.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                        tar\n",
              "56458  I'm too sleepy to drive.  \\tJe suis trop somnolent pour conduire.\\n\n",
              "11766          Is it hazardous?                     \\tEst-ce dangereux ?\\n\n",
              "24292       I have a dry cough.                   \\tJ'ai une toux sèche.\\n\n",
              "31722      That's a huge organ.           \\tC'est un organe gigantesque.\\n\n",
              "22502        You have problems.               \\tVous avez des problèmes.\\n\n",
              "24908       I'll call the cops.             \\tJe vais appeler les flics.\\n\n",
              "1115                Be content.                       \\tSois satisfait !\\n\n",
              "6669             This is basic.                         \\tC'est basique.\\n\n",
              "33032      What's the time now?       \\tQuelle heure est-il maintenant ?\\n\n",
              "50984   The event is on Monday.          \\tL'évènement se déroule lundi.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NH3ajyu685L",
        "colab_type": "text"
      },
      "source": [
        "# make CharSet\n",
        "글자수 Set을 만들면 쉽게 중복을 안 셀수 있다..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujlWc32s2I4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_vocab = set()\n",
        "\n",
        "for line in lines.src: # 1줄씩 읽기\n",
        "  for char in line: # 1개씩 읽기\n",
        "    src_vocab.add(char)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcm3u4Dp7ZDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5be8b0d-d354-4a3f-9e1f-5be964f8402f"
      },
      "source": [
        "src_vocab"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'é',\n",
              " '’',\n",
              " '€'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EbCoUbO7aMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGYSWk_-AUq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_vocab_size = len(src_vocab ) + 1\n",
        "tar_vocab_size = len(tar_vocab ) + 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcWZlq9AqQs",
        "colab_type": "text"
      },
      "source": [
        "# 글자단위 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3KVfERZA6QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1jKyr0OBDdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e7e2673-52cb-47fa-903b-e806a1917756"
      },
      "source": [
        "src_to_index"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 3,\n",
              " '!': 20,\n",
              " '\"': 53,\n",
              " '$': 26,\n",
              " '%': 38,\n",
              " '&': 28,\n",
              " \"'\": 23,\n",
              " ',': 13,\n",
              " '-': 33,\n",
              " '.': 43,\n",
              " '/': 37,\n",
              " '0': 77,\n",
              " '1': 18,\n",
              " '2': 52,\n",
              " '3': 17,\n",
              " '4': 11,\n",
              " '5': 27,\n",
              " '6': 16,\n",
              " '7': 73,\n",
              " '8': 64,\n",
              " '9': 45,\n",
              " ':': 32,\n",
              " '?': 7,\n",
              " 'A': 46,\n",
              " 'B': 14,\n",
              " 'C': 63,\n",
              " 'D': 70,\n",
              " 'E': 54,\n",
              " 'F': 60,\n",
              " 'G': 19,\n",
              " 'H': 58,\n",
              " 'I': 71,\n",
              " 'J': 40,\n",
              " 'K': 67,\n",
              " 'L': 35,\n",
              " 'M': 56,\n",
              " 'N': 49,\n",
              " 'O': 78,\n",
              " 'P': 30,\n",
              " 'Q': 5,\n",
              " 'R': 24,\n",
              " 'S': 75,\n",
              " 'T': 2,\n",
              " 'U': 10,\n",
              " 'V': 68,\n",
              " 'W': 57,\n",
              " 'X': 34,\n",
              " 'Y': 51,\n",
              " 'Z': 65,\n",
              " 'a': 62,\n",
              " 'b': 41,\n",
              " 'c': 69,\n",
              " 'd': 48,\n",
              " 'e': 39,\n",
              " 'f': 66,\n",
              " 'g': 47,\n",
              " 'h': 31,\n",
              " 'i': 61,\n",
              " 'j': 42,\n",
              " 'k': 15,\n",
              " 'l': 50,\n",
              " 'm': 29,\n",
              " 'n': 22,\n",
              " 'o': 21,\n",
              " 'p': 76,\n",
              " 'q': 72,\n",
              " 'r': 9,\n",
              " 's': 12,\n",
              " 't': 44,\n",
              " 'u': 25,\n",
              " 'v': 36,\n",
              " 'w': 8,\n",
              " 'x': 59,\n",
              " 'y': 4,\n",
              " 'z': 55,\n",
              " 'é': 1,\n",
              " '’': 6,\n",
              " '€': 74}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAGrR2dOBEe9",
        "colab_type": "text"
      },
      "source": [
        "# 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Pg3bZ1NKnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "178b8bcb-1dff-4c18-c65b-83e680320109"
      },
      "source": [
        "encoder_input = []\n",
        "for line in lines.src:\n",
        "  temp_X = []\n",
        "  for w in line:\n",
        "    temp_X.append(src_to_index[w])\n",
        "  encoder_input.append(temp_X)\n",
        "\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19, 21, 43], [58, 61, 43], [58, 61, 43], [24, 25, 22, 20], [24, 25, 22, 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Yiny9iO_SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ea0cc7ff-ee8d-45df-842a-62ff3bc2d890"
      },
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "  temp_X = []\n",
        "  for w in line:\n",
        "    temp_X.append(tar_to_index[w])\n",
        "  decoder_input.append(temp_X)\n",
        "\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85, 22, 101, 53, 59, 4], [85, 105, 101, 43, 84, 96, 53, 59, 4], [85, 105, 101, 43, 84, 96, 95, 4], [85, 18, 34, 84, 78, 80, 72, 59, 4], [85, 18, 34, 84, 78, 93, 45, 72, 59, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Zh8DzARdm0",
        "colab_type": "text"
      },
      "source": [
        "## \\<SOS> 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efi2VJ4oPPtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ecb6037c-dd8f-4a77-d8d9-3110353ce09c"
      },
      "source": [
        "decoder_target = []\n",
        "\n",
        "for line in lines.tar:\n",
        "  t = 0\n",
        "  temp_x = []\n",
        "  \n",
        "  for w in line:\n",
        "    if t>0:\n",
        "      temp_x.append(tar_to_index[w])\n",
        "    t += 1\n",
        "\n",
        "  decoder_target.append(temp_x)\n",
        "\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22, 101, 53, 59, 4], [105, 101, 43, 84, 96, 53, 59, 4], [105, 101, 43, 84, 96, 95, 4], [18, 34, 84, 78, 80, 72, 59, 4], [18, 34, 84, 78, 93, 45, 72, 59, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AXel6sYSFOT",
        "colab_type": "text"
      },
      "source": [
        "# 길이 맞추기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhXR3UuPRzxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea005119-b007-44e2-9ee6-0d6bafad1bcd"
      },
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCunp5lSUe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRvEOkRUSv4i",
        "colab_type": "text"
      },
      "source": [
        "# 모든 벡터를 one-hot 으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEq9Ke7Ss5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN88SSswTQ50",
        "colab_type": "text"
      },
      "source": [
        "# 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUOtYLByTmDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHgfhCAT8T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "# 은닉 상태와 게이트"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH_DXKWeiWij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ , _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dVUNmZJjzmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0f2efda5-7456-4a27-b229-4cd96f7b106a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 79)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 106)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 344064      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  371712      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 106)    27242       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 743,018\n",
            "Trainable params: 743,018\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtG5VNPAkJxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc80b898-bb49-46c8-f782-89000b0bc14e"
      },
      "source": [
        "model.fit(x = [encoder_input, decoder_input], y = decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.7833 - val_loss: 0.6960\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.4916 - val_loss: 0.5647\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.4097 - val_loss: 0.5011\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3632 - val_loss: 0.4627\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3320 - val_loss: 0.4320\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3106 - val_loss: 0.4146\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2938 - val_loss: 0.4010\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2802 - val_loss: 0.3922\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2690 - val_loss: 0.3850\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2595 - val_loss: 0.3796\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2511 - val_loss: 0.3766\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2437 - val_loss: 0.3732\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2369 - val_loss: 0.3713\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2308 - val_loss: 0.3696\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2252 - val_loss: 0.3704\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2199 - val_loss: 0.3686\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2150 - val_loss: 0.3701\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2105 - val_loss: 0.3698\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2064 - val_loss: 0.3705\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2022 - val_loss: 0.3735\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1985 - val_loss: 0.3725\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1948 - val_loss: 0.3742\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1914 - val_loss: 0.3755\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1882 - val_loss: 0.3769\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1850 - val_loss: 0.3801\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1821 - val_loss: 0.3840\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1793 - val_loss: 0.3859\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1764 - val_loss: 0.3855\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1740 - val_loss: 0.3890\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1713 - val_loss: 0.3913\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1690 - val_loss: 0.3937\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.1666 - val_loss: 0.3984\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1643 - val_loss: 0.3985\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1622 - val_loss: 0.4032\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1602 - val_loss: 0.4048\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1581 - val_loss: 0.4085\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1563 - val_loss: 0.4111\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1542 - val_loss: 0.4127\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1525 - val_loss: 0.4178\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1508 - val_loss: 0.4197\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1491 - val_loss: 0.4237\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1475 - val_loss: 0.4257\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1460 - val_loss: 0.4292\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1444 - val_loss: 0.4330\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1430 - val_loss: 0.4333\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1414 - val_loss: 0.4366\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1402 - val_loss: 0.4403\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1388 - val_loss: 0.4429\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1377 - val_loss: 0.4449\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1364 - val_loss: 0.4477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd02ebfdf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYKsxhYyiKA",
        "colab_type": "text"
      },
      "source": [
        "# 번역기 모델의 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvIGNJFWnV3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련된 모델을 재사용\n",
        "encoder_model = Model(inputs = encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q2WWWwOy9ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전 시점의 상태들을 저장\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "# 다음 단어를 예측하기 위해 초기 상태를 이전 시점의 상태로 사용 이는 뒤의 함수에서 구현\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs] + decoder_states)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93_u1_Il6nOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items()) # 코드 주의"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb1i0GPR1jCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <sos>에 해당하는 원 - 핫 벡터 생성\n",
        "  target_seq = np.zeros((1,1, tar_vocab_size))\n",
        "  target_seq[0,0, tar_to_index['\\t']] = 1\n",
        "  \n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예척 결과를 문자로 반환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos> 이거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "      stop_condition=True\n",
        "    \n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1, tar_vocab_size))\n",
        "    target_seq[0,0,sampled_token_index] = 1\n",
        "\n",
        "    # 현재 시점의 상태 저장\n",
        "    states_value = [h,c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k7FUz5d4SR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bdf10315-915b-4dc3-928d-d187c25285bf"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * '-')\n",
        "  print(\"입력 문장 : \", lines.src[seq_index])\n",
        "  print(\"정답 문장 : \", lines.tar[seq_index][1:len(lines.tar[seq_index])-1])\n",
        "  print(\"번역기가 변역한 문장 : \", decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장 :  Run!\n",
            "정답 문장 :  Cours !\n",
            "번역기가 변역한 문장 :  Cours !\n",
            "-----------------------------------\n",
            "입력 문장 :  I left.\n",
            "정답 문장 :  Je suis partie.\n",
            "번역기가 변역한 문장 :  Je suis bonne.\n",
            "-----------------------------------\n",
            "입력 문장 :  Call us.\n",
            "정답 문장 :  Appelez-nous !\n",
            "번역기가 변역한 문장 :  Appelle-nous !\n",
            "-----------------------------------\n",
            "입력 문장 :  How nice!\n",
            "정답 문장 :  Comme c'est gentil !\n",
            "번역기가 변역한 문장 :  Comme c'est bonne !\n",
            "-----------------------------------\n",
            "입력 문장 :  Turn left.\n",
            "정답 문장 :  Tourne à gauche.\n",
            "번역기가 변역한 문장 :  Attrapez ça !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL-0WO9E5ajI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05cf5d53-0496-4737-e18d-c19a4f0b3cf9"
      },
      "source": [
        "encoder_input[3:4].shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 24, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwDEhXkp5b2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b18f309-9077-4a1a-874d-6f7ed63fcb21"
      },
      "source": [
        "encoder_input[3].shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGgIDLh5fx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}