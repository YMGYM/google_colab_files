{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_With_Deep_Learning_Prcatice.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nNoW8pZY0eUm",
        "7NH3ajyu685L",
        "BvcWZlq9AqQs",
        "YAGrR2dOBEe9",
        "i9Zh8DzARdm0",
        "TRvEOkRUSv4i",
        "VeYKsxhYyiKA"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOsArqOp590PB2g4YX7H4pR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/google_colab_files/blob/master/NLP_With_Deep_Learning_Prcatice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QilqMbGmmR9N",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "이것은 https://wikidocs.net/24996 의 실습입니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYrLI2hzJIr_",
        "colab_type": "text"
      },
      "source": [
        "# Session1 : 글자 단위의 Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNoW8pZY0eUm",
        "colab_type": "text"
      },
      "source": [
        "## import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWf9OW3M0fzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmvJ8THj0q6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "with http.request(\"GET\", url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
        "  shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "  zip_ref.extractall(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSPHK-Fe1ZGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf918d4a-f17b-4f1d-bf2b-ab640b690d8a"
      },
      "source": [
        "lines = pd.read_csv(\"fra.txt\", names=['src', 'tar', 'copy'], sep='\\t')\n",
        "len(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "178009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtx2LlHG11Ss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "2b9b82d5-6276-47d1-b2c6-90a6b25b2c1f"
      },
      "source": [
        "lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "      <th>copy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178004</th>\n",
              "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178005</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178006</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178007</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178008</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178009 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      src  ...                                               copy\n",
              "0                                                     Go.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1                                                     Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "2                                                     Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "3                                                    Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4                                                    Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "...                                                   ...  ...                                                ...\n",
              "178004  Top-down economics never works, said Obama. \"T...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178005  A carbon footprint is the amount of carbon dio...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178006  Death is something that we're often discourage...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "178007  Since there are usually multiple websites on a...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "178008  If someone who doesn't know your background sa...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "\n",
              "[178009 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdufWppi1_mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = lines.loc[:, 'src':'tar']\n",
        "lines = lines[0:60000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDRTjHID2IFa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "ba5f0dad-57c8-486d-bf81-148b07184289"
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23761</th>\n",
              "      <td>He took a big risk.</td>\n",
              "      <td>Il a pris un gros risque.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57305</th>\n",
              "      <td>She showed me his album.</td>\n",
              "      <td>Elle m'a montré son album.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47038</th>\n",
              "      <td>Do you believe in UFOs?</td>\n",
              "      <td>Croyez-vous aux OVNIs ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31318</th>\n",
              "      <td>Open up the package.</td>\n",
              "      <td>Ouvrez le paquet.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38301</th>\n",
              "      <td>They're not all busy.</td>\n",
              "      <td>Elles ne sont pas toutes occupées.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8529</th>\n",
              "      <td>I'm not joking.</td>\n",
              "      <td>Je ne plaisante pas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7316</th>\n",
              "      <td>Can I have one?</td>\n",
              "      <td>Puis-je en avoir un ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33577</th>\n",
              "      <td>You're almost right.</td>\n",
              "      <td>Vous avez presque raison.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6001</th>\n",
              "      <td>I'm not going.</td>\n",
              "      <td>Je ne m'en vais pas.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51034</th>\n",
              "      <td>The middle one is mine.</td>\n",
              "      <td>Celui du milieu est le mien.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                 tar\n",
              "23761       He took a big risk.           Il a pris un gros risque.\n",
              "57305  She showed me his album.          Elle m'a montré son album.\n",
              "47038   Do you believe in UFOs?             Croyez-vous aux OVNIs ?\n",
              "31318      Open up the package.                   Ouvrez le paquet.\n",
              "38301     They're not all busy.  Elles ne sont pas toutes occupées.\n",
              "8529            I'm not joking.                Je ne plaisante pas.\n",
              "7316            Can I have one?               Puis-je en avoir un ?\n",
              "33577      You're almost right.           Vous avez presque raison.\n",
              "6001             I'm not going.                Je ne m'en vais pas.\n",
              "51034   The middle one is mine.        Celui du milieu est le mien."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C47CDqOhP0mG",
        "colab_type": "text"
      },
      "source": [
        "## Make Symbol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI4n40nPP2tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "762328e9-bbe2-477e-8ae6-f76f0ad00009"
      },
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t' + x + '\\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56458</th>\n",
              "      <td>I'm too sleepy to drive.</td>\n",
              "      <td>\\tJe suis trop somnolent pour conduire.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11766</th>\n",
              "      <td>Is it hazardous?</td>\n",
              "      <td>\\tEst-ce dangereux ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24292</th>\n",
              "      <td>I have a dry cough.</td>\n",
              "      <td>\\tJ'ai une toux sèche.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31722</th>\n",
              "      <td>That's a huge organ.</td>\n",
              "      <td>\\tC'est un organe gigantesque.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22502</th>\n",
              "      <td>You have problems.</td>\n",
              "      <td>\\tVous avez des problèmes.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24908</th>\n",
              "      <td>I'll call the cops.</td>\n",
              "      <td>\\tJe vais appeler les flics.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>Be content.</td>\n",
              "      <td>\\tSois satisfait !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6669</th>\n",
              "      <td>This is basic.</td>\n",
              "      <td>\\tC'est basique.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33032</th>\n",
              "      <td>What's the time now?</td>\n",
              "      <td>\\tQuelle heure est-il maintenant ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50984</th>\n",
              "      <td>The event is on Monday.</td>\n",
              "      <td>\\tL'évènement se déroule lundi.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                        tar\n",
              "56458  I'm too sleepy to drive.  \\tJe suis trop somnolent pour conduire.\\n\n",
              "11766          Is it hazardous?                     \\tEst-ce dangereux ?\\n\n",
              "24292       I have a dry cough.                   \\tJ'ai une toux sèche.\\n\n",
              "31722      That's a huge organ.           \\tC'est un organe gigantesque.\\n\n",
              "22502        You have problems.               \\tVous avez des problèmes.\\n\n",
              "24908       I'll call the cops.             \\tJe vais appeler les flics.\\n\n",
              "1115                Be content.                       \\tSois satisfait !\\n\n",
              "6669             This is basic.                         \\tC'est basique.\\n\n",
              "33032      What's the time now?       \\tQuelle heure est-il maintenant ?\\n\n",
              "50984   The event is on Monday.          \\tL'évènement se déroule lundi.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NH3ajyu685L",
        "colab_type": "text"
      },
      "source": [
        "## make CharSet\n",
        "글자수 Set을 만들면 쉽게 중복을 안 셀수 있다..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujlWc32s2I4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_vocab = set()\n",
        "\n",
        "for line in lines.src: # 1줄씩 읽기\n",
        "  for char in line: # 1개씩 읽기\n",
        "    src_vocab.add(char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcm3u4Dp7ZDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5be8b0d-d354-4a3f-9e1f-5be964f8402f"
      },
      "source": [
        "src_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'é',\n",
              " '’',\n",
              " '€'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EbCoUbO7aMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGYSWk_-AUq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_vocab_size = len(src_vocab ) + 1\n",
        "tar_vocab_size = len(tar_vocab ) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcWZlq9AqQs",
        "colab_type": "text"
      },
      "source": [
        "## 글자단위 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3KVfERZA6QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1jKyr0OBDdm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e7e2673-52cb-47fa-903b-e806a1917756"
      },
      "source": [
        "src_to_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 3,\n",
              " '!': 20,\n",
              " '\"': 53,\n",
              " '$': 26,\n",
              " '%': 38,\n",
              " '&': 28,\n",
              " \"'\": 23,\n",
              " ',': 13,\n",
              " '-': 33,\n",
              " '.': 43,\n",
              " '/': 37,\n",
              " '0': 77,\n",
              " '1': 18,\n",
              " '2': 52,\n",
              " '3': 17,\n",
              " '4': 11,\n",
              " '5': 27,\n",
              " '6': 16,\n",
              " '7': 73,\n",
              " '8': 64,\n",
              " '9': 45,\n",
              " ':': 32,\n",
              " '?': 7,\n",
              " 'A': 46,\n",
              " 'B': 14,\n",
              " 'C': 63,\n",
              " 'D': 70,\n",
              " 'E': 54,\n",
              " 'F': 60,\n",
              " 'G': 19,\n",
              " 'H': 58,\n",
              " 'I': 71,\n",
              " 'J': 40,\n",
              " 'K': 67,\n",
              " 'L': 35,\n",
              " 'M': 56,\n",
              " 'N': 49,\n",
              " 'O': 78,\n",
              " 'P': 30,\n",
              " 'Q': 5,\n",
              " 'R': 24,\n",
              " 'S': 75,\n",
              " 'T': 2,\n",
              " 'U': 10,\n",
              " 'V': 68,\n",
              " 'W': 57,\n",
              " 'X': 34,\n",
              " 'Y': 51,\n",
              " 'Z': 65,\n",
              " 'a': 62,\n",
              " 'b': 41,\n",
              " 'c': 69,\n",
              " 'd': 48,\n",
              " 'e': 39,\n",
              " 'f': 66,\n",
              " 'g': 47,\n",
              " 'h': 31,\n",
              " 'i': 61,\n",
              " 'j': 42,\n",
              " 'k': 15,\n",
              " 'l': 50,\n",
              " 'm': 29,\n",
              " 'n': 22,\n",
              " 'o': 21,\n",
              " 'p': 76,\n",
              " 'q': 72,\n",
              " 'r': 9,\n",
              " 's': 12,\n",
              " 't': 44,\n",
              " 'u': 25,\n",
              " 'v': 36,\n",
              " 'w': 8,\n",
              " 'x': 59,\n",
              " 'y': 4,\n",
              " 'z': 55,\n",
              " 'é': 1,\n",
              " '’': 6,\n",
              " '€': 74}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAGrR2dOBEe9",
        "colab_type": "text"
      },
      "source": [
        "## 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Pg3bZ1NKnV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "178b8bcb-1dff-4c18-c65b-83e680320109"
      },
      "source": [
        "encoder_input = []\n",
        "for line in lines.src:\n",
        "  temp_X = []\n",
        "  for w in line:\n",
        "    temp_X.append(src_to_index[w])\n",
        "  encoder_input.append(temp_X)\n",
        "\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19, 21, 43], [58, 61, 43], [58, 61, 43], [24, 25, 22, 20], [24, 25, 22, 20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Yiny9iO_SR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ea0cc7ff-ee8d-45df-842a-62ff3bc2d890"
      },
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "  temp_X = []\n",
        "  for w in line:\n",
        "    temp_X.append(tar_to_index[w])\n",
        "  decoder_input.append(temp_X)\n",
        "\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85, 22, 101, 53, 59, 4], [85, 105, 101, 43, 84, 96, 53, 59, 4], [85, 105, 101, 43, 84, 96, 95, 4], [85, 18, 34, 84, 78, 80, 72, 59, 4], [85, 18, 34, 84, 78, 93, 45, 72, 59, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Zh8DzARdm0",
        "colab_type": "text"
      },
      "source": [
        "## \\<SOS> 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efi2VJ4oPPtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ecb6037c-dd8f-4a77-d8d9-3110353ce09c"
      },
      "source": [
        "decoder_target = []\n",
        "\n",
        "for line in lines.tar:\n",
        "  t = 0\n",
        "  temp_x = []\n",
        "  \n",
        "  for w in line:\n",
        "    if t>0:\n",
        "      temp_x.append(tar_to_index[w])\n",
        "    t += 1\n",
        "\n",
        "  decoder_target.append(temp_x)\n",
        "\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22, 101, 53, 59, 4], [105, 101, 43, 84, 96, 53, 59, 4], [105, 101, 43, 84, 96, 95, 4], [18, 34, 84, 78, 80, 72, 59, 4], [18, 34, 84, 78, 93, 45, 72, 59, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AXel6sYSFOT",
        "colab_type": "text"
      },
      "source": [
        "## 길이 맞추기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhXR3UuPRzxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea005119-b007-44e2-9ee6-0d6bafad1bcd"
      },
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDCunp5lSUe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRvEOkRUSv4i",
        "colab_type": "text"
      },
      "source": [
        "## 모든 벡터를 one-hot 으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEq9Ke7Ss5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN88SSswTQ50",
        "colab_type": "text"
      },
      "source": [
        "## 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUOtYLByTmDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EHgfhCAT8T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "# 은닉 상태와 게이트"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH_DXKWeiWij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ , _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dVUNmZJjzmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "0f2efda5-7456-4a27-b229-4cd96f7b106a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 79)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 106)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 344064      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  371712      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 106)    27242       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 743,018\n",
            "Trainable params: 743,018\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtG5VNPAkJxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc80b898-bb49-46c8-f782-89000b0bc14e"
      },
      "source": [
        "model.fit(x = [encoder_input, decoder_input], y = decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.7833 - val_loss: 0.6960\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.4916 - val_loss: 0.5647\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.4097 - val_loss: 0.5011\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3632 - val_loss: 0.4627\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3320 - val_loss: 0.4320\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.3106 - val_loss: 0.4146\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2938 - val_loss: 0.4010\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2802 - val_loss: 0.3922\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2690 - val_loss: 0.3850\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2595 - val_loss: 0.3796\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2511 - val_loss: 0.3766\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2437 - val_loss: 0.3732\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2369 - val_loss: 0.3713\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2308 - val_loss: 0.3696\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2252 - val_loss: 0.3704\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2199 - val_loss: 0.3686\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2150 - val_loss: 0.3701\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2105 - val_loss: 0.3698\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2064 - val_loss: 0.3705\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.2022 - val_loss: 0.3735\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1985 - val_loss: 0.3725\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1948 - val_loss: 0.3742\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1914 - val_loss: 0.3755\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1882 - val_loss: 0.3769\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1850 - val_loss: 0.3801\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1821 - val_loss: 0.3840\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1793 - val_loss: 0.3859\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1764 - val_loss: 0.3855\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1740 - val_loss: 0.3890\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1713 - val_loss: 0.3913\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1690 - val_loss: 0.3937\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.1666 - val_loss: 0.3984\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1643 - val_loss: 0.3985\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1622 - val_loss: 0.4032\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1602 - val_loss: 0.4048\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1581 - val_loss: 0.4085\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1563 - val_loss: 0.4111\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1542 - val_loss: 0.4127\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1525 - val_loss: 0.4178\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1508 - val_loss: 0.4197\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1491 - val_loss: 0.4237\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1475 - val_loss: 0.4257\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1460 - val_loss: 0.4292\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1444 - val_loss: 0.4330\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1430 - val_loss: 0.4333\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1414 - val_loss: 0.4366\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1402 - val_loss: 0.4403\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1388 - val_loss: 0.4429\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1377 - val_loss: 0.4449\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1364 - val_loss: 0.4477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd02ebfdf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYKsxhYyiKA",
        "colab_type": "text"
      },
      "source": [
        "## 번역기 모델의 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvIGNJFWnV3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 훈련된 모델을 재사용\n",
        "encoder_model = Model(inputs = encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q2WWWwOy9ZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전 시점의 상태들을 저장\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "# 다음 단어를 예측하기 위해 초기 상태를 이전 시점의 상태로 사용 이는 뒤의 함수에서 구현\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs] + decoder_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93_u1_Il6nOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items()) # 코드 주의"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb1i0GPR1jCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <sos>에 해당하는 원 - 핫 벡터 생성\n",
        "  target_seq = np.zeros((1,1, tar_vocab_size))\n",
        "  target_seq[0,0, tar_to_index['\\t']] = 1\n",
        "  \n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예척 결과를 문자로 반환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos> 이거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "      stop_condition=True\n",
        "    \n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1, tar_vocab_size))\n",
        "    target_seq[0,0,sampled_token_index] = 1\n",
        "\n",
        "    # 현재 시점의 상태 저장\n",
        "    states_value = [h,c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k7FUz5d4SR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bdf10315-915b-4dc3-928d-d187c25285bf"
      },
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * '-')\n",
        "  print(\"입력 문장 : \", lines.src[seq_index])\n",
        "  print(\"정답 문장 : \", lines.tar[seq_index][1:len(lines.tar[seq_index])-1])\n",
        "  print(\"번역기가 변역한 문장 : \", decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장 :  Run!\n",
            "정답 문장 :  Cours !\n",
            "번역기가 변역한 문장 :  Cours !\n",
            "-----------------------------------\n",
            "입력 문장 :  I left.\n",
            "정답 문장 :  Je suis partie.\n",
            "번역기가 변역한 문장 :  Je suis bonne.\n",
            "-----------------------------------\n",
            "입력 문장 :  Call us.\n",
            "정답 문장 :  Appelez-nous !\n",
            "번역기가 변역한 문장 :  Appelle-nous !\n",
            "-----------------------------------\n",
            "입력 문장 :  How nice!\n",
            "정답 문장 :  Comme c'est gentil !\n",
            "번역기가 변역한 문장 :  Comme c'est bonne !\n",
            "-----------------------------------\n",
            "입력 문장 :  Turn left.\n",
            "정답 문장 :  Tourne à gauche.\n",
            "번역기가 변역한 문장 :  Attrapez ça !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL-0WO9E5ajI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05cf5d53-0496-4737-e18d-c19a4f0b3cf9"
      },
      "source": [
        "encoder_input[3:4].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 24, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwDEhXkp5b2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b18f309-9077-4a1a-874d-6f7ed63fcb21"
      },
      "source": [
        "encoder_input[3].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24, 79)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsRbpqU4FwBy",
        "colab_type": "text"
      },
      "source": [
        "# Session2 : 단어를 쓰는 Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvP3P6UDJG0J",
        "colab_type": "text"
      },
      "source": [
        "## 파일 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGgIDLh5fx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBv77JrQF5sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "http = urllib3.PoolManager()\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "filename = 'fra-eng.zip'\n",
        "path = os.getcwd()\n",
        "zipfilename = os.path.join(path, filename)\n",
        "\n",
        "with http.request(\"GET\", url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:\n",
        "  shutil.copyfileobj(r, out_file)\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "  zip_ref.extractall(path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9c7NbipF6bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이번엔 33000개의 샘플을 사용함\n",
        "num_samples = 33000"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maj4g85AI5cs",
        "colab_type": "text"
      },
      "source": [
        "## 각종 전처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTPpRqrzIeeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2yFXHwdI23X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentence(sent):\n",
        "  # 위에서 구현한 함수 호출\n",
        "  sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백을 만듦\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # 의도한 글자를 제외하고는 전부 공백으로 변환한다.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "\n",
        "  return sent"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ph4AiiSJj1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3580cc20-2476-47d6-e9da-e56b14626746"
      },
      "source": [
        "# 전처리 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "\n",
        "print(preprocess_sentence(en_sent))\n",
        "print(preprocess_sentence(fr_sent).encode('utf-8'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "have you had dinner ?\n",
            "b'avez vous deja dine ?'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klkEhOwbKpof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open('fra.txt', \"r\" ) as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      # 데이터 분리\n",
        "      src_line, tar_line, _ = line.strip().split(\"\\t\")\n",
        "      # 데이터 전처리\n",
        "      src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
        "\n",
        "      tar_line = preprocess_sentence(tar_line)\n",
        "      tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "      tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(src_line_input)\n",
        "      decoder_input.append(tar_line_input)\n",
        "      decoder_target.append(tar_line_target)\n",
        "\n",
        "      if i == num_samples -1 : \n",
        "        break\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-keLVHFMbHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2AC9Y9hN6oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c7361c0f-38c6-4e31-9084-20be61de5b8c"
      },
      "source": [
        "print(sents_en_in[:5])\n",
        "print(sents_fra_in[:5])\n",
        "print(sents_fra_out[:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
            "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
            "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC7sOd7BOAwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5oIj8NYO2sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpbSe2M9PU2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a3f02c5c-b4a7-4f87-e7ab-4b4f9bcb803f"
      },
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)\n",
        "print(decoder_target.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33000, 8)\n",
            "(33000, 16)\n",
            "(33000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqoAZptSPl3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80ddca22-f02d-4424-a259-cbfb1efea30d"
      },
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어 집합의 크기 : 4663, 프랑스어 단어 집합의 크기 : 8038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMKZJWF-WWqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORFh_0FAQD0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dc2690d-1b5f-4db7-b80f-63d7031869ca"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[27111 27136  9816 ... 31663 30833 26311]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DG4SuZoQTRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THGz6zLuQcAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ed1926c4-3d04-4f60-85a8-35ca5ba7d219"
      },
      "source": [
        "print(encoder_input[30097])\n",
        "print(decoder_input[30097])\n",
        "print(decoder_target[30097])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  2  86  59 180   1   0   0   0]\n",
            "[  2  11  14 152 272   1   0   0   0   0   0   0   0   0   0   0]\n",
            "[ 11  14 152 272   1   3   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNcWCWCuQiuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b7358dc-6f4f-4aa1-8b0a-b8599b0359d7"
      },
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print(n_of_val)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbpNQrc_RxX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ssh9AXySES6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9ea9cea1-5e48-442b-9b46-972dfd00569a"
      },
      "source": [
        "print(encoder_input_train.shape)\n",
        "print(decoder_input_train.shape)\n",
        "print(decoder_target_train.shape)\n",
        "print(encoder_input_test.shape)\n",
        "print(decoder_input_test.shape)\n",
        "print(decoder_target_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29700, 8)\n",
            "(29700, 16)\n",
            "(29700, 16)\n",
            "(3300, 8)\n",
            "(3300, 16)\n",
            "(3300, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffMSR4zDSHIv",
        "colab_type": "text"
      },
      "source": [
        "## Import Seq2Seq Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPOymwD0sS06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bm4sU1OsrfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedding 크기 고정\n",
        "latent_dim = 50"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HII0yZZCtOQv",
        "colab_type": "text"
      },
      "source": [
        "### 인코더 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nruNz9-EuXPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = Input(shape=(None, ))\n",
        "enc_emb = Embedding(src_vocab_size, latent_dim)(encoder_inputs)\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉, 셀 상태 반환"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQKUh3UNvqOC",
        "colab_type": "text"
      },
      "source": [
        "### 디코더 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5y6c-mIwIxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, ))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, latent_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states) # 인코더의 은닉 상태를 초기 상태로 사용.\n",
        "\n",
        "decoder_dense = Dense(tar_vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L7hV_3fL3lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSyFBtiPMMin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "7d4f1e63-fa98-458e-89d8-025713f35130"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 50)     233150      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 50)     401900      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 8038)   409938      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,085,388\n",
            "Trainable params: 1,085,388\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8EeU7abMN-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=['acc'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Zv8BITkMmsw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5f78628-2bb5-440e-d0e1-835b4c504cdd"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test), batch_size = 128, epochs = 50)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 18s 78ms/step - loss: 3.1995 - acc: 0.6043 - val_loss: 1.9805 - val_acc: 0.7116\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.7473 - acc: 0.7250 - val_loss: 1.6603 - val_acc: 0.7413\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.5529 - acc: 0.7470 - val_loss: 1.5311 - val_acc: 0.7517\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 1.4450 - acc: 0.7639 - val_loss: 1.4460 - val_acc: 0.7727\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.3546 - acc: 0.7786 - val_loss: 1.3631 - val_acc: 0.7840\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.2850 - acc: 0.7886 - val_loss: 1.3181 - val_acc: 0.7882\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.2290 - acc: 0.7984 - val_loss: 1.2692 - val_acc: 0.7962\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.1820 - acc: 0.8061 - val_loss: 1.2270 - val_acc: 0.8047\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.1430 - acc: 0.8117 - val_loss: 1.2128 - val_acc: 0.8062\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.1090 - acc: 0.8163 - val_loss: 1.1655 - val_acc: 0.8126\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.0783 - acc: 0.8200 - val_loss: 1.1584 - val_acc: 0.8135\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.0502 - acc: 0.8239 - val_loss: 1.1271 - val_acc: 0.8188\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 1.0246 - acc: 0.8269 - val_loss: 1.1115 - val_acc: 0.8204\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 1.0004 - acc: 0.8299 - val_loss: 1.0913 - val_acc: 0.8220\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.9780 - acc: 0.8329 - val_loss: 1.0685 - val_acc: 0.8263\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.9569 - acc: 0.8356 - val_loss: 1.0554 - val_acc: 0.8276\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 16s 70ms/step - loss: 0.9373 - acc: 0.8381 - val_loss: 1.0391 - val_acc: 0.8291\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.9192 - acc: 0.8405 - val_loss: 1.0317 - val_acc: 0.8312\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.9030 - acc: 0.8431 - val_loss: 1.0186 - val_acc: 0.8328\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.8881 - acc: 0.8451 - val_loss: 1.0044 - val_acc: 0.8343\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8735 - acc: 0.8474 - val_loss: 1.0170 - val_acc: 0.8333\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8604 - acc: 0.8490 - val_loss: 0.9810 - val_acc: 0.8391\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.8485 - acc: 0.8510 - val_loss: 0.9840 - val_acc: 0.8395\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8369 - acc: 0.8531 - val_loss: 0.9717 - val_acc: 0.8412\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8258 - acc: 0.8546 - val_loss: 0.9659 - val_acc: 0.8426\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8149 - acc: 0.8565 - val_loss: 0.9781 - val_acc: 0.8397\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.8043 - acc: 0.8581 - val_loss: 0.9623 - val_acc: 0.8431\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7944 - acc: 0.8598 - val_loss: 0.9519 - val_acc: 0.8443\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7851 - acc: 0.8616 - val_loss: 0.9494 - val_acc: 0.8454\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7759 - acc: 0.8627 - val_loss: 0.9384 - val_acc: 0.8477\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7671 - acc: 0.8646 - val_loss: 0.9419 - val_acc: 0.8462\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7588 - acc: 0.8660 - val_loss: 0.9529 - val_acc: 0.8431\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7513 - acc: 0.8673 - val_loss: 0.9339 - val_acc: 0.8473\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7438 - acc: 0.8689 - val_loss: 0.9290 - val_acc: 0.8477\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7369 - acc: 0.8702 - val_loss: 0.9301 - val_acc: 0.8472\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.7302 - acc: 0.8715 - val_loss: 0.9185 - val_acc: 0.8506\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.7238 - acc: 0.8729 - val_loss: 0.9364 - val_acc: 0.8484\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7178 - acc: 0.8742 - val_loss: 0.9147 - val_acc: 0.8512\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7118 - acc: 0.8752 - val_loss: 0.9053 - val_acc: 0.8530\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7060 - acc: 0.8767 - val_loss: 0.9067 - val_acc: 0.8535\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.7001 - acc: 0.8779 - val_loss: 0.9106 - val_acc: 0.8523\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 16s 69ms/step - loss: 0.6947 - acc: 0.8791 - val_loss: 0.9052 - val_acc: 0.8534\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6887 - acc: 0.8800 - val_loss: 0.9054 - val_acc: 0.8532\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6828 - acc: 0.8812 - val_loss: 0.9050 - val_acc: 0.8540\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6773 - acc: 0.8821 - val_loss: 0.9043 - val_acc: 0.8529\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6714 - acc: 0.8833 - val_loss: 0.8972 - val_acc: 0.8556\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6661 - acc: 0.8843 - val_loss: 0.8936 - val_acc: 0.8552\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6609 - acc: 0.8852 - val_loss: 0.8948 - val_acc: 0.8551\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6558 - acc: 0.8862 - val_loss: 0.9063 - val_acc: 0.8541\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 16s 68ms/step - loss: 0.6502 - acc: 0.8871 - val_loss: 0.8901 - val_acc: 0.8557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd7ddbf908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5N7lJkLNGS9",
        "colab_type": "text"
      },
      "source": [
        "## 번역기 동작시키기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Z7y9FZVT0R",
        "colab_type": "text"
      },
      "source": [
        "### 변형된 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woJvzIjARPJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMh8OeunRUTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련때 사용한 임베딩 층 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음단어 예측에 사용하기 위해 예전 상태 결과를 재사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_inputs)\n",
        "decoder_state2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0pdklZDSKKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디코더 정의\n",
        "decoder_model = Model([decoder_inputs] + decoder_state_inputs,[decoder_outputs2] + decoder_state2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z49r4y8MTMyc",
        "colab_type": "text"
      },
      "source": [
        "### 동작을 위한 해석함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WTDya5KST7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <sos> 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition=False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0,-1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    decoded_sentence += ' ' + sampled_char\n",
        "\n",
        "    if (sampled_char == '<eos>' or len(decoded_sentence) > 50):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현 시점의 예측 결과를 다음 시점의 입력으로 사용\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0,0] = sampled_token_index\n",
        "\n",
        "    # 현 시점의 상태 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YFSOaS0UYHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원문의 정수 시퀀스를 변환\n",
        "def seq2src(input_seq):\n",
        "  temp = ''\n",
        "  for i in input_seq:\n",
        "    if(i != 0):\n",
        "      temp = temp + index_to_src[i] + ' '\n",
        "  return temp"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxAEsDQ8U9O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2tar(input_seq):\n",
        "  temp = ''\n",
        "  for i in input_seq:\n",
        "    if((i != 0 and i != tar_to_index['<sos>']) and i!= tar_to_index['<eos>']):\n",
        "      temp = temp + index_to_tar[i] + ' '\n",
        "\n",
        "  return temp"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZH5nfNwVOc3",
        "colab_type": "text"
      },
      "source": [
        "### 훈련 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwVBn80bVS1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5b2e1898-483b-42d6-fd2c-ee7e2c09bcb3"
      },
      "source": [
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  \n",
        "  print('원문 : ', seq2src(encoder_input_train[seq_index]))\n",
        "  print(\"변역문 : \", seq2tar(decoder_input_train[seq_index]))\n",
        "  print(\"예측문 : \", decoded_sentence[: -5]) # <eos> 떼기\n",
        "  print('\\n')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  you are a student . \n",
            "변역문 :  tu es un etudiant . \n",
            "예측문 :   tu es un nouveau . \n",
            "\n",
            "\n",
            "원문 :  i deserve it . \n",
            "변역문 :  je le merite . \n",
            "예측문 :   je le coup . \n",
            "\n",
            "\n",
            "원문 :  let s hit the road . \n",
            "변역문 :  on se casse ! \n",
            "예측문 :   nous faites une journee . \n",
            "\n",
            "\n",
            "원문 :  we re fighting . \n",
            "변역문 :  nous sommes en train de nous battre . \n",
            "예측문 :   nous nous en train de ne nous faut pas . \n",
            "\n",
            "\n",
            "원문 :  i was happy then . \n",
            "변역문 :  j etais heureux alors . \n",
            "예측문 :   j etais heureux pour vous . \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aB7NtaqV4qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}