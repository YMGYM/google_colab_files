{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_Detection_First.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+DQFjYnuZKQ6duzUrE5tJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/google_colab_files/blob/master/Object_Detection_First.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rdf3cEYOG5"
      },
      "source": [
        "# Intro\n",
        "<p> 이미지 검출 테스트 </p>\n",
        "https://deepbaksuvision.github.io/Modu_ObjectDetection/posts/01_00_What_is_Object_Detection.html 를 사용했습니다\n",
        "\n",
        "https://www.kaggle.com/aruchomu/yolo-v3-object-detection-in-tensorflow\n",
        "\n",
        "도 참고했습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H_6kQ8jZq1z"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSL8bvSOx-kI"
      },
      "source": [
        "# HyperParams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUUHCR2qxrfc"
      },
      "source": [
        "_BATCH_NORM_DECAY = 0.9\n",
        "_BATCH_NORM_EPSILON = 1e-05\n",
        "_LEAKY_RELU = 0.1\n",
        "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
        "            (30, 61), (62, 45), (59, 119),\n",
        "            (116, 90), (156, 198), (373, 326)]\n",
        "_MODEL_SIZE = (416, 416)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7kkaLjVyAx0"
      },
      "source": [
        "def batch_norm(inputs, training, data_format):\n",
        "  return tf.layers.batch_normalization(inputs=inputs, axis=1 if data_format == 'channels_first' else 3, momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, scale=True, training=training)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3kMTtpZVX-H"
      },
      "source": [
        "def fixed_padding(inputs, kernel_size, data_format):\n",
        "  pad_total = kernal_size - 1\n",
        "  pad_beg = pad_total // 2\n",
        "  pad_end = pad_total - pad_beg\n",
        "\n",
        "  if data_format == 'channels_first':\n",
        "    padded_inputs = tf.pad(inputs, [[0,0], [0,0], [pad_beg, pad_end], [pad_beg, pad_end]])\n",
        "\n",
        "  else:\n",
        "    padded_inputs = tf.pad(inputs, [[0,0], [pad_beg, pad_end], [pad_beg, pad_end], [0,0]])\n",
        "\n",
        "  return padded_inputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPsHt4VvWQNt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}