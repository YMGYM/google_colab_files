{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzcLlYELFK1EvV1QLXvWL1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YMGYM/google_colab_files/blob/master/NLP_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsSa241-rl4w",
        "colab_type": "text"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "384QfLOXgiVE",
        "colab_type": "text"
      },
      "source": [
        "이 노트북은 Made With ML의 교육 파일 https://github.com/madewithml/basics/blob/master/notebooks/14_Embeddings/14_TF_Embeddings.ipynb 을 연습한 노트북입니다.\n",
        "\n",
        "This notebook is for practice of https://github.com/madewithml/basics/blob/master/notebooks/14_Embeddings/14_TF_Embeddings.ipynb in Made With ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOiYQNXhg4pJ",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ncvv6OlhWtT",
        "colab_type": "text"
      },
      "source": [
        "## Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eh7PhtbhYdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SHePsMnhiCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_FILE = 'harrypotter.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUY_sZYshkWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# github repository 에서 데이터를 읽어 옴\n",
        "url = \"https://raw.githubusercontent.com/madewithml/basics/master/data/harrypotter.txt\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(DATA_FILE, 'wb') as fp:\n",
        "  fp.write(html) # 파일로 생성"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36SKzufrh1dn",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTxcva1Qh4d3",
        "colab_type": "code",
        "outputId": "e7a2e7a8-cdc2-4d2d-9ea1-f50396dfa0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkkxIjvjiYNk",
        "colab_type": "code",
        "outputId": "8d742ad5-90c7-40f6-ee09-3c3ac24f11e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk; nltk.download('punkt')\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unhgi0n3kjYa",
        "colab_type": "text"
      },
      "source": [
        "nltk.punkt 는 자연어 토큰화 모듈.\n",
        "토큰화에 대한 자세한 설명은 [여기](https://wikidocs.net/21698)를 참조.\n",
        "요약하면 주어진 corpus를 사용하기 쉽게 정제하는 것.\n",
        "`tf.keras.preprocessing.text.text_to_word_sequence` 는 문장을 단어의 연속으로 바꿔 줌. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEVjkXWqioFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsMj0L42jhYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz6uEhiyjjNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILTERS = \"!\\\"'#$%&()*+,_./:;<=>?@[\\\\]^_'{|}~\"\n",
        "LOWER = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKOlaVDQmGfq",
        "colab_type": "code",
        "outputId": "f3e70939-28aa-4f3c-ca5c-73dd2e8b3455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "with open(DATA_FILE, encoding='cp1252') as fp:\n",
        "  book = fp.read()\n",
        "sentences = tokenizer.tokenize(book)\n",
        "print(f\"{len(sentences)} sentences\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15640 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEJCet51mmTx",
        "colab_type": "code",
        "outputId": "f6922c09-fe68-4c9c-cf4a-10bd18260e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print (sentences[12])\n",
        "sentences = [text_to_word_sequence(text=sentence,filters=FILTERS,lower=LOWER, split=\" \") for sentence in sentences]\n",
        "print(sentences[12])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "They turned right, into a wide driveway that led off the lane.\n",
            "['they', 'turned', 'right', 'into', 'a', 'wide', 'driveway', 'that', 'led', 'off', 'the', 'lane']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qasb1GhZnTnZ",
        "colab_type": "text"
      },
      "source": [
        "`' '` 을 기점으로 단어를 잘라 리스트로 변환함</br>\n",
        "`lower` 옵션으로 소문자화 설정."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a18o4iwoZF4",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koIl9gLWUJAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUhQYZNHUNyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 100 # embedding 벡터\n",
        "WINDOW = 5\n",
        "MIN_COUNT = 3 # 3회 이하로 나온 단어는 무시\n",
        "SKIP_GRAM = 1 # 0 = CBOW\n",
        "NEGATIVE_SAMPLING = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vag5O1GKUktd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v = Word2Vec(sentences=sentences,size = EMBEDDING_DIM, window=WINDOW, min_count = MIN_COUNT, sg = SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVJm_IZ1U5If",
        "colab_type": "code",
        "outputId": "8eb0a211-835a-4a3d-f2cd-f1500c1809ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(w2v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=4943, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0AWVAATVBKM",
        "colab_type": "code",
        "outputId": "2dc848a6-f9ce-4b99-f2ae-7354f267d698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "w2v.wv.get_vector(\"potter\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04382599, -0.27061546,  0.1651173 ,  0.11518585,  0.08209284,\n",
              "        0.29084224,  0.41149804,  0.15002549,  0.15954678, -0.15583111,\n",
              "        0.21830478,  0.33232954,  0.09824262,  0.13917533, -0.1396302 ,\n",
              "       -0.25955015, -0.16083549,  0.02623774,  0.17311276, -0.0435692 ,\n",
              "        0.24526185,  0.2566217 , -0.29358414, -0.06039868, -0.3891427 ,\n",
              "        0.08209246, -0.04794239, -0.0095009 ,  0.05358456,  0.47284657,\n",
              "        0.25039336,  0.01511135,  0.36297756,  0.28031012, -0.36281002,\n",
              "        0.5458123 ,  0.07694073,  0.02720371,  0.02810892, -0.38364294,\n",
              "        0.21260844,  0.26286042, -0.13364011,  0.12455881, -0.15269653,\n",
              "        0.00127807,  0.5376269 , -0.01063405,  0.14180158,  0.06000757,\n",
              "       -0.22659217, -0.02594471, -0.08970959,  0.07681642, -0.33292103,\n",
              "       -0.27242723, -0.12953316,  0.41518903,  0.08366511,  0.08306436,\n",
              "       -0.3427147 , -0.0542339 , -0.14626692,  0.19276895,  0.10108715,\n",
              "       -0.5280813 ,  0.21871641, -0.0438563 ,  0.6344262 , -0.04046528,\n",
              "        0.43855774,  0.18738458, -0.31301588,  0.07744867, -0.3607888 ,\n",
              "        0.24133484,  0.10970028,  0.21268803, -0.1011205 ,  0.08479226,\n",
              "        0.11671434,  0.29477632, -0.03454557, -0.27455473, -0.16062602,\n",
              "       -0.06504466, -0.47952947,  0.10469721, -0.05177385, -0.2147482 ,\n",
              "        0.15395242, -0.4058646 ,  0.31636655,  0.27328384, -0.44677508,\n",
              "       -0.08251934, -0.12646663,  0.00253108, -0.13800706,  0.18248431],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfhT37LWEgj",
        "colab_type": "code",
        "outputId": "9b92ac23-6beb-4a31-c3e8-1a4ccfe92a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "w2v.wv.most_similar(positive=\"scar\", topn=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pain', 0.9584817886352539),\n",
              " ('forehead', 0.9346109628677368),\n",
              " ('burning', 0.9248462915420532),\n",
              " ('cold', 0.924383282661438),\n",
              " ('burned', 0.921999454498291)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfefBrYDWZcO",
        "colab_type": "code",
        "outputId": "5cd551b9-3601-44e4-ae0b-0cc5e0584ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "w2v.wv.save_word2vec_format('model.bin', binary=True)\n",
        "w2v = KeyedVectors.load_word2vec_format('model.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SNkCSRIWuMb",
        "colab_type": "text"
      },
      "source": [
        "# Pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnn5iRK7f0db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AnPV0G2gMhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "788a652c-5464-4448-cbb2-b530a191adc6"
      },
      "source": [
        "np.random.seed(SEED)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b045c5f70805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'SEED' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXM02EFEgYwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNLkvMOgebs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\n",
        "  for word in words:\n",
        "    index = embeddings.index2word.index(word)\n",
        "    plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
        "    plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppj2tgVDg0B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resp = urlopen('http://nlp.stanford.edu/data/glove.6B.zip')\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\n",
        "zipfile.namelist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6xUgedchGpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_file = f\"glove.6B.{EMBEDDING_DIM}d.txt\"\n",
        "zipfile.extract(embeddings_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho-vis9piawN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(embeddings_file, 'r') as fp:\n",
        "  for i in range(1,80):\n",
        "    line = next(fp)\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype='float32')\n",
        "    print(f\"word : {word}\")\n",
        "    # print(f\"embedding: \\n{embedding}\")\n",
        "    # print(f\"embedding dim: {len(embedding)}\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6XLJWbzjSz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# local 디렉토리에 저장\n",
        "word2vec_output_file = f\"{embeddings_file}.word2vec\"\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNLwOODpkLt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 임베딩 파일 오픈\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwAAlnFk--e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (king - man) + woman = ? == man : king = woman : ?\n",
        "glove.most_similar(positive=['woman', 'king'], negative=['man'], topn=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq3Dqt9AlzEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (we - they) + you = ?\n",
        "glove.most_similar(positive=['you', 'we'], negative=['they'], topn=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzkgZ0tgmiLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# go : went = do : ?\n",
        "glove.most_similar(positive=['do', 'went'], negative=['go'], topn=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JhegEB5nJzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 근접 벡터\n",
        "glove.wv.most_similar(positive=\"we\", topn=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmPLVEmvnguP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 그래프를 위한 차원 제거"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS_eB1Z7nm4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = glove[glove.wv.vocab]\n",
        "pca = PCA(n_components=2) # 2차원으로 변환 (특이값분해)\n",
        "pca_results = pca.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lMFPtD0n44k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_embeddings(words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove, pca_results=pca_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5laQV80oG3W",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtbMhu86cSx1",
        "colab_type": "text"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj_8YKtGcUUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import urllib\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-vxtAkLerbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_FILE = 'news.csv'\n",
        "INPUT_FEATURE = 'title'\n",
        "OUTPUT_FEATURE = 'category'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov3KtEqRezB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/madewithml/basics/master/data/news.csv\"\n",
        "response = urllib.request.urlopen(url)\n",
        "html = response.read()\n",
        "with open(DATA_FILE, 'wb') as fp:\n",
        "  fp.write(html)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBaRdNmRfYPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load_data\n",
        "df = pd.read_csv(DATA_FILE, header=0)\n",
        "X = df[INPUT_FEATURE].values\n",
        "y = df[OUTPUT_FEATURE].values\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNusbQbwfoyR",
        "colab_type": "text"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLdFTWQVf7s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "# 자료를 셀 때 사용하는 객체\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7LzODcpgAO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15 # validation 데이터의 비중인듯\n",
        "TEST_SIZE = 0.15\n",
        "SHUFFLE = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2bkY7QygFql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_test_split(X, y, val_size, test_size, shuffle):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, shuffle=shuffle)\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, stratify=y_train, shuffle=shuffle)\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b1IaskujJhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X = X, y=y, val_size=VAL_SIZE, test_size=TEST_SIZE, shuffle=SHUFFLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMgowMO9jaAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_counts = dict(collections.Counter(y))\n",
        "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print(f\"Sample point: {X_train[0]} -> {y_train[0]}\")\n",
        "print(f\"Classes: {class_counts}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyoY7ld3nTLC",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8HB0oqn6iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRUB4XEGpM9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILTERS = \"!\\\"'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
        "LOWER = True\n",
        "CHAR_LEVEL = False # Default 가 False 인데?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHjqVS3RpY2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(indices, tokenizer):\n",
        "  return \" \".join([tokenizer.index_word[index] for index in indices])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dZBRXRIp014",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input vectorizer\n",
        "X_tokenizer = Tokenizer(filters=FILTERS, lower=LOWER, char_level=CHAR_LEVEL, oov_token='<UNK>')\n",
        "# oov => out-of-vocaburay : 없는 단어는 저걸로 처리\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMjlWJ9jqTgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = len(X_tokenizer.word_index) + 1\n",
        "print(f\"# tokens: {vocab_size}\")\n",
        "print(X_tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLirNHDgqjyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_text = X_train[0]\n",
        "X_train = np.array(X_tokenizer.texts_to_sequences(X_train))\n",
        "X_val = np.array(X_tokenizer.texts_to_sequences(X_val))\n",
        "X_test = np.array(X_tokenizer.texts_to_sequences(X_test))\n",
        "preprocessed_text = decode(X_train[0], X_tokenizer)\n",
        "print(f\"{original_text}\\n\\t=> {preprocessed_text}\\n\\t => {X_train[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr3mVo_FvL2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_tokenizer.texts_to_sequences(X_train))\n",
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUA-0-hkwOpu",
        "colab_type": "text"
      },
      "source": [
        "Label Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SYzj0jYe7vD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh6_DjQwe-aA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = LabelEncoder()\n",
        "y_tokenizer = y_tokenizer.fit(y_train)\n",
        "classes = list(y_tokenizer.classes_)\n",
        "print(f\"classes: {classes}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jHr07sofrXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 라벨을 토큰에 매칭\n",
        "y_train = y_tokenizer.transform(y_train)\n",
        "y_val = y_tokenizer.transform(y_val)\n",
        "y_test = y_tokenizer.transform(y_test)\n",
        "print(f\"y_train[0]: {y_train[0]}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvULGQAHgBm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class weights\n",
        "counts = np.bincount(y_train) # 숫자를 세는 메소드\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print(f\"class counts: {counts}, \\nclass weights: {class_weights}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMbyTGB5gj-l",
        "colab_type": "text"
      },
      "source": [
        "## Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWXmmfcHuIxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REHnwKNGuRVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "FILTER_SIZES = [2,3,4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EArQuNOfuXat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make custom data loader\\\n",
        "class DataGenerator(Sequence):\n",
        "  def __init__(self, X, y, batch_size, max_filter_size, shuffle=False):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.batch_size = batch_size\n",
        "    self.max_filter_size = max_filter_size\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "  \n",
        "  def __len__(self):\n",
        "    # of batches...\n",
        "    return math.ceil(len(self.X)/self.batch_size)\n",
        "\n",
        "  def __str__(self):\n",
        "    return(f\"<DataGenerator( \"\\\n",
        "           f\"batch_size = {self.batch_size}, \"\\\n",
        "           f\"batches={len(self)}, \"\\\n",
        "           f\"shuffle={self.shuffle})>\")\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    # Generate batch data\n",
        "\n",
        "    # Gather indices for this batch\n",
        "    batch_indices = self.epoch_indices[index * self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "    # 배치 데이터 생성\n",
        "    X, y = self.create_batch(batch_indices=batch_indices)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    # 매 에포크 마다 indices 생성\n",
        "    self.epoch_indices = np.arange(len(self.X))\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.epoch_indices)\n",
        "\n",
        "  def create_batch(self, batch_indices):\n",
        "    # 배치를 직접적으로..\n",
        "\n",
        "    # batch_indices 를 마스크처럼 활용\n",
        "    X = self.X[batch_indices]\n",
        "    y = self.y[batch_indices]\n",
        "\n",
        "    # 패딩\n",
        "    max_seq_len = max(self.max_filter_size, max([len(x) for x in X]))\n",
        "    # padding=\"post\"로 데이터의 뒷 부분에 패딩 추가 \n",
        "    X = pad_sequences(X, padding=\"post\", maxlen=max_seq_len)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmq5U5Pxuexe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 제너레이터\n",
        "training_generator = DataGenerator(X=X_train, y=y_train, batch_size=BATCH_SIZE, max_filter_size=max(FILTER_SIZES), shuffle=SHUFFLE)\n",
        "validation_generator = DataGenerator(X=X_val, y=y_val, batch_size=BATCH_SIZE, max_filter_size=max(FILTER_SIZES), shuffle=False)\n",
        "testing_generator = DataGenerator(X=X_test, y=y_test, batch_size=BATCH_SIZE, max_filter_size=max(FILTER_SIZES), shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgpRi2N7xTdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"training_generator:{training_generator}\")\n",
        "print(f\"validation_generator:{validation_generator}\")\n",
        "print(f\"testing_generator:{testing_generator}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae-MjkXCxvY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 사용해보기\n",
        "print(f\"num test batches: {len(testing_generator)}\")\n",
        "for i, batch in enumerate(testing_generator):\n",
        "  if i >= 10: break\n",
        "  print(f\"batch{i} | x: {batch[0].shape}, y: {batch[1].shape}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYiheOiay3jg",
        "colab_type": "text"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbKSH5eJ2plf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpPvShBP3BfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Input(shape=(10)) # (batch_size, max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeF0p8WK3Hh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4JQ4Jqp3JgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings\n",
        "embedding = Embedding(input_dim=10, # vocab size\n",
        "                      output_dim=100 # embedding size\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NMbf7_L3TM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding(x).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7VDemqi3ZXs",
        "colab_type": "text"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcmWoREysD6o",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc0nuh5KsFmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Concatenate, Conv1D, Dense, Dropout, Embedding, GlobalMaxPool1D, Input\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZVlsFob6L3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, filter_sizes, num_filters, hidden_dim, dropout_p, num_classes, freeze_embeddings=False):\n",
        "    super(CNN, self).__init__(name=\"cnn\")\n",
        "\n",
        "    # Embeddings\n",
        "    self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, trainable=not freeze_embeddings)\n",
        "\n",
        "    # Convolutional filters\n",
        "    self.convs = []\n",
        "    self.pools = []\n",
        "    for filter_size in filter_sizes:\n",
        "      conv = Conv1D(filters=num_filters, kernal_size = filter_size, padding='same', activation=\"relu\")\n",
        "      pool = GlobalMaxPool1D(data_format='channels_last')\n",
        "      self.convs.append(conv)\n",
        "      self.pools.append(pool)\n",
        "\n",
        "    self.cancat = Concatenate(axis=1)\n",
        "\n",
        "    # FC layers\n",
        "    self.fc1 = Dense(units=hidden_dim, activation='relu')\n",
        "    self.dropout = Dropout(rate=dropout_p)\n",
        "    self.fc2 = Dense(units=num_classes, activation='softmax')\n",
        "\n",
        "def call(self, x_in, training=False):\n",
        "  # Embedding\n",
        "  x_emb = self.embedding(x_in)\n",
        "\n",
        "  # Convoultions\n",
        "  convs = []\n",
        "  for i in range(len(self.convs)):\n",
        "    z = self.convs[i](x_emb)\n",
        "    z = self.pools[i](z)\n",
        "    convs.append(z)\n",
        "  \n",
        "  # Concatenate\n",
        "  z_cat = self.concat(convs)\n",
        "\n",
        "  # Fc\n",
        "  z = self.fc1(z_cat)\n",
        "  if training:\n",
        "    # 드롭아웃은 훈련때만 적용\n",
        "    z = self.dropout(z, training = training)\n",
        "  y_pred = self.fc2(z)\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def summary(self, input_shape):\n",
        "  x_in = Input(shape=input_shape, name='X')\n",
        "  summary = Model(inputs=x_in, outputs=self.call(x_in), name=self.name)\n",
        "  return plot_model(summary, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbAchV6ICelO",
        "colab_type": "text"
      },
      "source": [
        "## gloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDvbQlcHCly9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_embeddings(embeddings_file):\n",
        "  embeddings = {}\n",
        "  with open(embeddings_file, \"r\") as fp:\n",
        "    for index, line in enumerate(fp):\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      embedding = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings[word] = embedding\n",
        "  return embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE5GX0ZHEaF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "  for word, i in word_index.items():\n",
        "    embedding_vector = embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piU94NCvFB-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
        "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
        "embedding_matrix = make_embeddings_matrix(embeddings=glove_embeddings,\n",
        "                                          word_index=X_tokenizer.word_index,\n",
        "                                          embedding_dim=EMBEDDING_DIM)\n",
        "print(f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDup4CRgGUgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}